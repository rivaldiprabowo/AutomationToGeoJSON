{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automation Excel to CSV and GeoJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import json\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Application to Export Excel into GeoJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Function Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_column_names(columns): # Ensure column names are unique by appending suffix.\n",
    "    seen = {}\n",
    "    new_columns = []\n",
    "    for col in columns:\n",
    "        if col in seen:\n",
    "            seen[col] += 1\n",
    "            new_columns.append(f\"{col}_{seen[col]}\")\n",
    "        else:\n",
    "            seen[col] = 0\n",
    "            new_columns.append(col)\n",
    "    return new_columns\n",
    "\n",
    "def clean_column_names(columns): #Standardize column names by capitalizing each word properly.\n",
    "    cleaned_columns = []\n",
    "    seen = {}\n",
    "    for col in columns:\n",
    "        col = str(col).strip()\n",
    "        col = \" \".join(word.capitalize() for word in col.split())\n",
    "        if col in seen:\n",
    "            seen[col] += 1\n",
    "            col = f\"{col} {seen[col]}\"\n",
    "        else:\n",
    "            seen[col] = 0\n",
    "        cleaned_columns.append(col)\n",
    "    return cleaned_columns\n",
    "\n",
    "def fix_coordinates(row, lat_col, lon_col): #Fix latitude and longitude values that may be in the wrong format.\n",
    "    lat, lon = row[lat_col], row[lon_col]\n",
    "    if pd.notna(lat) and abs(lat) > 90:\n",
    "        lat /= 1_000_000\n",
    "    if pd.notna(lon) and abs(lon) > 180:\n",
    "        lon /= 1_000_000\n",
    "    return pd.Series([lat, lon])\n",
    "\n",
    "def clean_geojson(gdf, output_path): #Save GeoDataFrame in a clean format GeoJSON file.\n",
    "    temp_path = output_path.replace(\".geojson\", \"_temp.geojson\")\n",
    "    gdf.to_file(temp_path, driver=\"GeoJSON\")\n",
    "\n",
    "    with open(temp_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        geojson_data = json.load(file)\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(geojson_data, file, indent=4)\n",
    "\n",
    "    print(f\"‚úÖ Saved: {output_path}\")\n",
    "\n",
    "def flatten_excel_to_geojson(file_path, output_folder): \n",
    "#Convert all sheets from an Excel file to GeoJSON, ensuring clean column names, valid geometries, and clean GeoJSON format\n",
    "    \n",
    "    # Load workbook\n",
    "    wb = load_workbook(file_path, data_only=True)\n",
    "\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        ws = wb[sheet_name]\n",
    "\n",
    "        # Unmerge cells and fill values\n",
    "        for merge in list(ws.merged_cells):\n",
    "            ws.unmerge_cells(str(merge))\n",
    "            top_left = ws.cell(merge.min_row, merge.min_col).value\n",
    "            for row in range(merge.min_row, merge.max_row + 1):\n",
    "                for col in range(merge.min_col, merge.max_col + 1):\n",
    "                    ws.cell(row, col, top_left)\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        data = list(ws.values)\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Identify the header row\n",
    "        header_index = df[df.apply(lambda x: x.astype(str).str.contains(\"NO\", case=False, na=False)).any(axis=1)].index[0]\n",
    "\n",
    "        # Use row 3 (index 2) as the header\n",
    "        df.columns = df.iloc[2].astype(str).str.strip()\n",
    "\n",
    "        # Remove empty columns\n",
    "        df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "        # Drop \"REKAP\" section if present\n",
    "        df = df.loc[:, ~df.columns.str.contains(\"REKAP\", case=False, na=False)]\n",
    "        df = df.drop(index=[0, 1, 4]).reset_index(drop=True)\n",
    "\n",
    "        # Merge first two rows if needed\n",
    "        merged_header = [a if a == b else f\"{a} {b}\" for a, b in zip(df.iloc[0], df.iloc[1])]\n",
    "\n",
    "        # Ensure column names are unique\n",
    "        df.columns = unique_column_names(merged_header)\n",
    "\n",
    "        # Remove the first two rows used for headers\n",
    "        df = df.drop(index=[0, 1]).reset_index(drop=True)\n",
    "\n",
    "        # Normalize column names for consistent detection\n",
    "        df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "        # Find Latitude & Longitude columns dynamically\n",
    "        lat_col = next((col for col in df.columns if \"latitude\" in col or \"lat\" in col), None)\n",
    "        lon_col = next((col for col in df.columns if \"longitude\" in col or \"lon\" in col), None)\n",
    "\n",
    "        if not lat_col or not lon_col:\n",
    "            print(f\"‚ö†Ô∏è Skipping '{sheet_name}' (No Latitude/Longitude columns)\")\n",
    "            continue  # Skip this sheet if Lat/Lon are missing\n",
    "\n",
    "        # Convert Lat/Lon to numeric first (forcing errors to NaN)\n",
    "        df[lat_col] = pd.to_numeric(df[lat_col], errors='coerce')\n",
    "        df[lon_col] = pd.to_numeric(df[lon_col], errors='coerce')\n",
    "\n",
    "        # Apply the fix function\n",
    "        df[[lat_col, lon_col]] = df.apply(fix_coordinates, axis=1, lat_col=lat_col, lon_col=lon_col)\n",
    "\n",
    "        # Remove rows where Lat/Lon are still missing\n",
    "        df = df.dropna(subset=[lat_col, lon_col]).reset_index(drop=True)\n",
    "\n",
    "        # Ensure geometry column exists before creating GeoDataFrame\n",
    "        df[\"geometry\"] = df.apply(\n",
    "            lambda row: Point(row[lon_col], row[lat_col]) if pd.notna(row[lon_col]) and pd.notna(row[lat_col]) else None,\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Drop rows where geometry is None\n",
    "        df = df.dropna(subset=[\"geometry\"]).reset_index(drop=True)\n",
    "\n",
    "        # Only create GeoDataFrame if there are valid geometries\n",
    "        if not df[\"geometry\"].isnull().all():\n",
    "            properties_cols = [col for col in df.columns if col not in [lat_col, lon_col, \"geometry\"]]\n",
    "            gdf = gpd.GeoDataFrame(df[properties_cols + [\"geometry\"]], crs=\"EPSG:4326\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Skipping '{sheet_name}' (No valid geometry found)\")\n",
    "            continue  # Skip processing this sheet if no valid geometries exist\n",
    "\n",
    "        # Apply column renaming after creating the GeoDataFrame\n",
    "        gdf.columns = clean_column_names(gdf.columns)\n",
    "\n",
    "        # Remove unwanted \"None_\" and \"None\" columns\n",
    "        gdf = gdf.loc[:, ~gdf.columns.str.match(r\"^None$|None_\", na=False)]\n",
    "\n",
    "        # Remove \" None\" from remaining column names\n",
    "        gdf.columns = gdf.columns.str.replace(r\"\\sNone\\b\", \"\", regex=True).str.strip()\n",
    "\n",
    "        # Create output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Define output file path\n",
    "        output_path = os.path.join(output_folder, f\"{sheet_name}.geojson\")\n",
    "\n",
    "        # Save the GeoJSON in a clean format\n",
    "        clean_geojson(gdf, output_path)\n",
    "\n",
    "    # Delete temporary files\n",
    "    for temp_file in glob.glob(os.path.join(output_folder, \"*_temp.geojson\")):\n",
    "        os.remove(temp_file)\n",
    "\n",
    "    print(\"üéâ All sheets processed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Run Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kanzi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: C:\\Users\\kanzi\\Documents\\Part Time Job\\Automation Codes\\check\\RAMBU.geojson\n",
      "‚úÖ Saved: C:\\Users\\kanzi\\Documents\\Part Time Job\\Automation Codes\\check\\PJU.geojson\n",
      "‚úÖ Saved: C:\\Users\\kanzi\\Documents\\Part Time Job\\Automation Codes\\check\\RPPJ.geojson\n",
      "‚úÖ Saved: C:\\Users\\kanzi\\Documents\\Part Time Job\\Automation Codes\\check\\PAGAR PENGAMAN.geojson\n",
      "‚úÖ Saved: C:\\Users\\kanzi\\Documents\\Part Time Job\\Automation Codes\\check\\MARKA.geojson\n",
      "‚úÖ Saved: C:\\Users\\kanzi\\Documents\\Part Time Job\\Automation Codes\\check\\WARNING LIGHT.geojson\n",
      "‚úÖ Saved: C:\\Users\\kanzi\\Documents\\Part Time Job\\Automation Codes\\check\\APILL.geojson\n",
      "‚ö†Ô∏è Skipping 'ZOSS' (No valid geometry found)\n",
      "‚úÖ Saved: C:\\Users\\kanzi\\Documents\\Part Time Job\\Automation Codes\\check\\FAS PENYEBERANGAN.geojson\n",
      "‚ö†Ô∏è Skipping 'RAMBU PORTABLE' (No Latitude/Longitude columns)\n",
      "‚ö†Ô∏è Skipping 'TRAFFIC CONE' (No Latitude/Longitude columns)\n",
      "‚ö†Ô∏è Skipping 'WATER BARRIER' (No Latitude/Longitude columns)\n",
      "‚ö†Ô∏è Skipping 'CERMIN TIKUNG' (No valid geometry found)\n",
      "üéâ All sheets processed successfully!\n"
     ]
    }
   ],
   "source": [
    "excel_file = r\"C:\\Users\\kanzi\\Documents\\Part Time Job\\Automation Codes\\01. Cileungsi - Cibeet.xlsx\"  # Fill with the path file of excel\n",
    "export_folder = r\"C:\\Users\\kanzi\\Documents\\Part Time Job\\Automation Codes\\check\"  # Fill with the path folder of export result\n",
    "flatten_excel_to_geojson(excel_file, export_folder) # Run the function!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
